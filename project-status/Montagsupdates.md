# Montagsupdates
_Im Rahmen der Projektf√∂rderung durch den [Prototype Fund](https://prototypefund.de) berichten wir w√∂chentlich √ºber unseren Fortschritt, neueste Updates zuerst._

## Woche 20 (Update zum 20. Juli)
### An diesen Milestones arbeiten wir gerade
 3. [Prognose-Berechnung entwickeln](https://github.com/dystonse/dystonse/milestone/3) (Die ist jetzt im Wesentlichen fertig!)
 4. [Routensuche neu implementieren](https://github.com/dystonse/dystonse/milestone/4)
 
### Das haben wir letzte Woche gemacht
 * Unserem kleinen Server auf dem Homeoffice-Schreibtisch ein Hardware-Upgrade verpasst (SSD statt Festplatte) und das System neu installiert. Jetzt l√§uft darauf der aktuellste Stand unseres Docker-Compose-Stacks und sammelt Fahrplan- und Echtzeitdaten, importiert Echtzeitupdates in die Datenbank, und erstellt Prognosen f√ºr aktuelle Fahrten, basierend auf den Echtzeitupdates.
 * Community-Building und Austausch mit anderen OpenSource-Entwickler\*innen und Verkehrsunternehmen.
 * Automatische Generierung (und Speichern in der Datenbank) von [Prognosen f√ºr zuk√ºnftige Fahrten auf Basis des Fahrplans](https://github.com/dystonse/dystonse-gtfs-data/blob/master/src/importer/scheduled_predictions_importer.rs), f√ºr maximal bis zu einem festgelegten Zeitraum (aktuell testweise ca. eine Woche) in die Zukunft. Das passiert in kleinen H√§ppchen immer zwischendurch, wenn gerade keine neuen Echtzeitdaten zum importieren da sind.
 * [Gro√üe Refactorings in dystonse-gtfs-data](https://github.com/dystonse/dystonse-gtfs-data/commit/a1ca4c59e794194bf4c8bf657385a21ecde6f8e3), vor allem neue Datenstrukturen, um Informationen √ºber die Qualit√§t der Prognosen besser speichern zu k√∂nnen.

### Das machen wir diese Woche
 * Neuimplementierung der Routensuche anfangen
 * Planungen f√ºr Frontend (eigenes Frontend anpassen und/oder Integration in fremde Anwendungen)

### Das bremst uns gerade
 * Ablenkung durch private Aufgaben und andere Jobs.
 * Die Anforderung f√ºr unsere zweite F√∂rdergeld-Auszahlung ist immer noch nicht angekommen.
 
### Das motiviert uns gerade
 * Endspurt :)

## Woche 19 (Update zum 13. Juli)
### An diesen Milestones arbeiten wir gerade
 3. [Prognose-Berechnung entwickeln](https://github.com/dystonse/dystonse/milestone/3)
 4. [Routensuche neu implementieren](https://github.com/dystonse/dystonse/milestone/4)
 
### Das haben wir letzte Woche gemacht
 * [Erweiterung des Import-Moduls](https://github.com/dystonse/dystonse-gtfs-data/commit/34c047745c208bb556784893a48930b62328e9e1#diff-2fd0d7be9788d256c26422411c7da3ac), so dass es Prognosen in die Datenbank speichert f√ºr alle Fahrten, von denen wir aktuelle Echtzeitdaten haben. Das Speichern ist noch etwas langsam, vor allem im Vergleich dazu wie schnell die eigentliche Berechnung passiert, aber funktioniert.
 * [Fallbacks f√ºr die Default-Prognosen](https://github.com/dystonse/dystonse-gtfs-data/commit/add94bf782c3cd64872c5ba08b4afbf112993c05#diff-333360f8a6ba23e9547ec998bca28eb5) implementiert, so dass die Abfrage auf jeden Fall immer eine Kurve zur√ºckgeben kann - ggf. nur nach Verkehrsmittel und Ankunft/Abfahrt gruppiert, wenn f√ºr die jeweiligen Zeit- und Streckenabschnitte zu wenig Daten da sind. Und f√ºr den Fall, dass wir dann immer noch zu wenig Daten h√§tten, ist die [n√§chste Fallback-L√∂sung](https://github.com/dystonse/dystonse-gtfs-data/commit/becd7f5b9c91d3cce397614476e9e21fa63de5e6#diff-333360f8a6ba23e9547ec998bca28eb5) jetzt der Durchschnitt aus allen Kurven, die wir haben.
 * Das [Docker-Setup](https://github.com/dystonse/dystonse-docker/tree/with-analyser) aktualisiert, so dass einmal am Tag automatisch die Kurven (sowohl default als auch linienspezifische) neu berechnet und exportiert werden.
 * Damit sind wir nun auch sehr nah am Ziel, dass Interessierte Menschen oder Unternehmen einfach [dystonse-docker](https://github.com/dystonse/dystonse-docker/) clonen und starten k√∂nnen, und innerhalb von Minuten einen kompletten lauff√§higen Stack erhalten. Bisher war da noch viel manuelles Tweaking n√∂tig sowie wochenlange Datensammlung, bevor eine Datenbasis f√ºr Prognosen bestand.
 * [Caching der zuletzt geladenen Fahrplan- und Analysen-Dateien](https://github.com/dystonse/dystonse-gtfs-data/commit/f144625b3ea666623e96b46378315053d96e6d0e) in unserem Importer/Analyser/Predictor, so dass die Dateien nur noch dann neu eingelesen werden, wenn sie sich ge√§ndert haben. Das spart zwar "nur" 10 bis 20 Sekunden Rechenzeit, aber bei einem Prozess, der sich alle zwei Minuten wiederholt, kommt da schon einiges zusammen.
 * [Abh√§ngigkeiten von `dystonse-gtfs-data`](https://github.com/dystonse/dystonse-gtfs-data/blob/master/Cargo.toml) etwas ausgemistet, d.h. einige Pakete durch leichtgewichtigere Versionen ersetzt oder in optionale Features ausgelagert, um die compile-Zeiten wieder k√ºrzer zu machen.
 * Ein l√§ngeres Gespr√§ch mit anderen Open-Source-Entwicklern gef√ºhrt, die auch an √ñPNV-Prognosen arbeiten m√∂chten. Vielleicht wird daraus mal eine Kooperation.
 
### Das machen wir diese Woche
 * Prognosen f√ºr alle Fahrten (nicht nur die, von denen wir Echtzeitupdates bekommen) automatisch generieren und in eine Datenbank speichern (wir testen noch, ob das mit MySQL schnell genug machbar ist, oder wir daf√ºr z.b. auf redis umsteigen).
 * Die (vorerst) letzten Schritte, um den Einsatz unsere Docker-Stacks zu vereinfachen: Default-Analyse-Ergebnisse beilegen und Dokumentation aufr√§umen.
 * Die eigentliche Routensuche anfangen zu implementieren (oder zumindest planen, wie sie strukturiert sein soll).
 * Genauer planen, wie die Schnittstelle zwischen Routensuche und Analyse/Prognose aussehen soll.
 * Zweites Zwischengespr√§ch mit der Prototypefund-Orga.
 * Gedanken dazu machen, was wir in den n√§chsten 7 Wochen noch erreichen k√∂nnen/wollen/werden, und wie es danach weiter geht.
 
### Das bremst uns gerade
 * Ablenkung durch private Aufgaben und andere Jobs
 * Langsame Hardware/langsame Datenbank
 
### Das motiviert uns gerade
 * Bald sind wir so weit, dass wir mit der Umsetzung der eigentlichen Routensuche anfangen k√∂nnen.
 * N√§chste Woche haben wir unseren ersten Coaching-Termin.

## Woche 18 (Update zum 6. Juli)
### An diesen Milestones arbeiten wir gerade
 2. [Statistische Analyse der gesammelten Echtzeit-Versp√§tungs-Daten](https://github.com/dystonse/dystonse/milestone/2)
 3. [Prognose-Berechnung entwickeln](https://github.com/dystonse/dystonse/milestone/3)
 
### Das haben wir letzte Woche gemacht
 * Viel Refactoring und Erweiterungen des Import-Moduls, so dass damit auch Prognosen basierend auf aktuell eintreffenden Echtzeitdaten angefragt und in die Datenbank gespeichert werden k√∂nnen. Das ist noch nicht fertig.
 * Planung f√ºr eine neue Struktur der Datenbank, um aktuelle Prognosen in separaten Tabellen zu speichern.
 * Teilweise diese Planung schon in einer lokalen Testinstanz der Datenbank umgesetzt.
 * Recherche zu m√∂glichen Erweiterungen des GTFS-Realtime-Formats, die wir verwenden oder selbst definieren k√∂nnten.

### Das machen wir diese Woche
 * Die angefangenen Erweiterungen der Datenbank und des Importer-Moduls fertig stellen.
 * Fallback-L√∂sungen f√ºr Prognosen definieren, f√ºr die wir keine ausreichend gro√üe Datenmenge als Grundlage haben.
 * Die automatische Erstellung von Analysen (Kurven) in unser Docker-Setup integrieren.
 * Kommunikation mit anderen OpenSource-Entwicklern aus dem Mobilit√§ts-OpenData-Bereich.

### Das bremst uns gerade
 * Ablenkung durch private Aufgaben und andere Jobs
 * Compilen innerhalb von Docker ist langsam, das nervt.

### Das motiviert uns gerade
 * Bald sind wir so weit, dass wir mit der Umsetzung der eigentlichen Routensuche anfangen k√∂nnen.


## Woche 17 (Update zum 29. Juni)
### An diesen Milestones arbeiten wir gerade
 2. [Statistische Analyse der gesammelten Echtzeit-Versp√§tungs-Daten](https://github.com/dystonse/dystonse/milestone/2)
 3. [Prognose-Berechnung entwickeln](https://github.com/dystonse/dystonse/milestone/3)

### Das haben wir letzte Woche gemacht
 * Die [Prognoseberechnung](https://github.com/dystonse/dystonse-gtfs-data/tree/master/src/predictor) (eigentlich keine Berechnung sondern eher ein gezieltes "Rausfischen" der passenden Wahrscheinlichkeitskurve aus der gesamten Menge, die im Voraus berechnet und gespeichert wurde) so weit fertig gestellt, dass man √ºber die Kommandozeile eine einzelne Prognose pro Ausf√ºhrung abfragen kann.
 * Einen neuen [Befehl f√ºr unser Analyse-Modul](https://github.com/dystonse/dystonse-gtfs-data/blob/master/src/analyser/curves.rs), der alle Kurven (sowohl f√ºr spezifische Linien und Haltestellen(paare), als auch die allgemeinen Kurven (nach Verkehrsmittel, Zeitraum und Streckenabschnitt)) berechnet und in einer Datei speichert, die dann vom Prognose-Modul gelesen werden kann. Das soll im laufenden Betrieb wahrscheinlich 1x t√§glich automatisch durchgef√ºhrt werden und dauert aktuell ca. 15 Minuten f√ºr alle Daten aus dem VBN.
 * Die [Dokumentation](https://github.com/dystonse/dystonse-gtfs-data/blob/master/README.md) mit Angaben zu den neuen Analyse- und Prognose-Befehlen erweitert.
 * Kommunikation mit anderen OpenSource-Entwicklern aus dem Mobilit√§ts-OpenData-Bereich.
 * Viel Arbeit am (De-)Serialisieren unserer Daten in Json, MessagePack und Ordnerstrukturen. Leider noch nicht ganz fertig, aber immerhin benutzbar.

### Das machen wir diese Woche
 * Einen Modus f√ºr das Prognose-Modul implementieren, in dem es dauerhaft l√§uft und jederzeit Anfragen √ºber eine Schnittstelle beantworten kann.
 * Vorher erst noch die Schnittstelle f√ºr diese Prognose-Anfragen genauer planen und definieren.

### Das bremst uns gerade
 * Die Hitze im (Dachgeschoss-)Arbeitszimmer (inzwischen geht's erstmal wieder)
 * Ablenkung durch private Aufgaben und andere Jobs

### Das motiviert uns gerade
 * Bald sind wir so weit, dass wir mit der Umsetzung der eigentlichen Routensuche anfangen k√∂nnen.
 

## Woche 16 (Update zum 22. Juni)
### An diesen Milestones arbeiten wir gerade
 2. [Statistische Analyse der gesammelten Echtzeit-Versp√§tungs-Daten](https://github.com/dystonse/dystonse/milestone/2)
 3. [Prognose-Berechnung entwickeln](https://github.com/dystonse/dystonse/milestone/3)

### Das haben wir letzte Woche gemacht
 * Die gr√∂√üte Aufr√§umaktion, die unser Code bisher gesehen hat. Es l√§sst sich nicht klar von den neuen Features trennen, aber allein `dystonse-gtfs-data` hatte in dieser Woche `22 files changed, 1705 insertions(+), 2078 deletions(-)`.
 * Unterteilung der Daten und Analysen nach Wochentag und Uhrzeit in [11 disjunkte `TimeSlots`](https://github.com/dystonse/dystonse-gtfs-data/blob/master/src/types/time_slots.rs) die dem [Wikipedia-Beispiel der Verkehrszeiten in Bottrop](https://de.wikipedia.org/wiki/Verkehrszeiten#Beispiele) nachempfunden sind.
 * [Allgemeinere Statistiken √ºber Versp√§tungen](https://github.com/dystonse/dystonse-gtfs-data/blob/master/src/analyser/default_curves.rs), gruppiert u.a. nach Verkehrsmittel-Typ, damit wir auch f√ºr die vielen Linien Prognosen erstellen k√∂nnen, f√ºr die wir gar keine Echtzeitdaten haben. Dabei betrachten wir Anfang, Mitte und Ende jeder Linie gesondert, nachdem [David Kriesel in seinem Vortrag zum 'BahnMining'](http://www.dkriesel.com/blog/2019/1229_video_und_folien_meines_36c3-vortrags_bahnmining) heraus gestellt hat, wie verschieden sich Versp√§tungen da auswirken
 * Die Analyse der Versp√§tungen und das Erzeugen der Grafiken sind nun sauber getrennt. Dabei funktioniert die Analyse immer noch, die Grafikerzeugung ist momentan nicht ganz einsatzbereit.
 * Die Analysen k√∂nnen jetzt in eine gro√üe maschinenlesbare Datei (MessagePack) oder Ordnerstrukturen mit sehr vielen (!) Dateien (MessagePack oder JSON) geschrieben werden. Dabei sind diverse Zwischenstufen konfigurierbar.
 * Das [Grundger√ºst f√ºr die Erstellung von Prognosen](https://github.com/dystonse/dystonse-gtfs-data/blob/master/src/predictor/mod.rs) steht nun.

### Das machen wir diese Woche
 * Prognosen! In dieser Woche sollen endlich erste eigene Prognosen entstehen. Dazu feht gar nicht mehr so viel Code.
 * Die Erstellung der Prognosen muss aber auch in ein gr√∂√üeres Framework mit API, Caching, etc. eingebunden werden. Da m√ºssen wir noch viel planen.
 * Es fehlt noch etwas Code, um die Analyse-Daten wieder einzulesen, wenn diese nicht in einer einzelnen Datei sondern einer Ordnerhierarchie vorliegen.
 * Unter anderem durch unseren [Blogpost vom 10.6.](http://blog.dystonse.org/analysis/2020/06/10/kurven.html) haben uns ein paar Zuschriften von Verkehrsverb√ºnden, Unternehmen und anderen OpenSource-Teams erreicht. Die wollen wir nun angemessen beantworten und schauen, welche Arten der Kooperation da m√∂glich sind.
 * Uns um Coaching-Termine k√ºmmern.
 
### Das bremst uns gerade
 * Das gute Wetter und die knapp 30¬∞C in unserem Arbeitszimmer

### Das motiviert uns gerade
 * Das gute Wetter
 * Dass wir bald eine neue Auszahlung beantragen k√∂nnen :)
 * Dass nur noch etwa 2 Monate verbleiben - das ist allerdings gleicherma√üen motivierend und be√§ngstigend, da noch so viel zu tun ist


## Woche 15 (Update zum 15. Juni)
### An diesen Milestones arbeiten wir gerade
 2. [Statistische Analyse der gesammelten Echtzeit-Versp√§tungs-Daten](https://github.com/dystonse/dystonse/milestone/2)
 3. [Prognose-Berechnung entwickeln](https://github.com/dystonse/dystonse/milestone/3)

### Das haben wir letzte Woche gemacht
 * Einen sehr ausf√ºhrlichen [Blogpost √ºber unsere statistischen Auswertungen](http://blog.dystonse.org/analysis/2020/06/10/kurven.html) geschrieben
 * Viele Detailverbesserungen an den grafischen Darstellungen gemacht und dabei viel √ºber [Gnuplot](http://www.gnuplot.info/) gelernt
 * Eine Metrik erdacht und implementiert, mit der sich die Unterschiedlichkeit mehrerer Wahrscheinlichkeitsverteilungen als Wert ausdr√ºcken l√§sst
 * Recherche zur Datenserialisierung mit Rust, um unsere Analysen maschinenlesbar zu speichern
 * √úberlegungen zu verschiedenen Prognoseverfahren je nach Verf√ºgbarkeit von Echtzeitdaten. Dabei haben wir unser Projekt nochmal auf vielen verschiedenen Detail-Leveln betrachtet und unsere Planung f√ºr die n√§chsten Wochen angepasst.

### Das machen wir diese Woche
 * Code aufr√§umen. In [dystonse-gtfs-data](https://github.com/dystonse/dystonse-gtfs-data) ist der Code zur Datenverarbeitung und zur grafischen Darstellung noch viel zu stark vermischt.
 * Implementierung der oben genannten Datenserialisierung mit [Serde](https://serde.rs/) / [MessagePack](https://msgpack.org/) oder [Protocol Buffers](https://developers.google.com/protocol-buffers)
 * Evtl. bereits erste Version einer einfachen Prognosekomponente, die auf den Analysen aufbaut (wie schon eine Woche zuvor gehofft).
 * Statistische Gesamtauswertungen mit vereinfachten Parametern (z.B. f√ºr alle Busse / alle Stra√üenbahnen, etc.), um ein Fallback f√ºr die (vielen!) Linien zu bieten, f√ºr die wir grunds√§tzlich keine Echtzeitdaten haben. Damit k√∂nnten wir auch schon die Neuimplementierung der Routensuche angehen.
 
### Das bremst uns gerade
 * Oft verzetteln wir uns in aufw√§ndigen L√∂sungen f√ºr Detailprobleme und verlieren dabei das gro√üe Ganze etwas aus den Augen. Diese L√∂sungen f√ºhlen sich dann zwar f√ºr den Moment wie ein wichtiger Erfolg an, aber bremsen ums im Gesamtverlauf.

### Das motiviert uns gerade
 * Der Blogpost wurde ganz gut geteilt und wir haben viel positives Feedback daf√ºr und ein paar neue Kontakte dadurch bekommen.
 * Die Reflektion zur Zielsetzung und den nun n√∂tigen Schritten wirft ein paar spannende, neue Aufgaben auf, die wir gerne angehen wollen.

## Woche 14 (Update zum 8. Juni)
### An diesen Milestones arbeiten wir gerade
 2. [Statistische Analyse der gesammelten Echtzeit-Versp√§tungs-Daten](https://github.com/dystonse/dystonse/milestone/2)
 3. [Prognose-Berechnung entwickeln](https://github.com/dystonse/dystonse/milestone/3)

### Das haben wir letzte Woche gemacht
 * Viel Arbeit an den statistischen Auswertungen und ihrer Visualisierung, darunter:
   * Rundungs-Artefakte in den Rohdaten gefunden und einen Workaround daf√ºr gefunden
   * Bessere Aufteilung der Rohdaten in Klassen von Anfangsversp√§tungen
   * Datenpunkte werden nicht mehr strikt in eine dieser Klassen zugeteilt, sondern gehen gewichtet in (bis zu) zwei benachbarte Klassen ein
   * Grafische Verbesserungen wie z.B. bessere Farbauswahl, verst√§ndlichere Legende, etc.
 * Durchschauen der generierten Kurven und manuelle Pr√ºfung auf Plausibilit√§t. Unter anderem haben wir aus charakteristischen Mustern in den Kurven das Vorhandensein einer Ampel direkt vor einer Bushaltestelle vorhergesagt und anschlie√üend mit Satellitenbildern best√§tigt.
 * Kleine [Erg√§nzung](https://github.com/rust-transit/gtfs-structure/pull/66) am GTFS-Parser.
 * Vorbereitung eines neuen Blogposts, der die Arbeit(-sergebnisse) der letzten zwei Wochen beschreibt. Dieser ist leider nicht mehr vor dem heutigen Update fertig geworden.

### Das machen wir diese Woche
 * Den Blogpost fertig stellen. Dazu fehlt noch eine ganze Menge Text, aber auch kleine Anpassungen an unserer Software um erkl√§rende Grafiken zu generieren.
 * Ausweitung unserer Analysen auf alle gesammelten Linien - bisher haben wir nur zwei Bus- und zwei Tramlinien aus Bremen und Oldenburg betrachtet.
 * Evtl. bereits erste Version einer einfachen Prognosekomponente, die auf den Analysen aufbaut.
 
### Das bremst uns gerade
 * Das √úbliche :/

### Das motiviert uns gerade
 * Die Kurven bildlich zu sehen best√§tigt weiterhin viele zuvor ungepr√ºfte Annahmen √ºber die Daten bzw. das Wesen von Versp√§tungen allgemein.
 * Bei den statistischen Methoden verlassen wir eigentlich deutlich unsere Comfort Zone - also den Bereich dessen, wo wir uns fachlich sicher f√ºhlen - und trotzdem geht es damit sehr reibungslos voran.


## Woche 13 (Update zum ~~1.~~ 2. Juni)
### An diesen Milestones arbeiten wir gerade
 1. [Kontinuierliche Versp√§tungs-Datensammlung planen, aufbauen und betreiben](https://github.com/dystonse/dystonse/milestone/1) (ab jetzt haupts√§chlich nur noch der "betreiben"-Anteil)
 2. [Statistische Analyse der gesammelten Echtzeit-Versp√§tungs-Daten](https://github.com/dystonse/dystonse/milestone/2)
 3. [Prognose-Berechnung entwickeln](https://github.com/dystonse/dystonse/milestone/3)
 
 ### Das haben wir letzte Woche gemacht 
 * Verschiedene Detailverbesserungen an den [Kurven](https://github.com/dystonse/dystonse-curves)-Strukturen.
 * Die Kurven um neue Funktionalit√§t erg√§nzt: Gewichtete Interpolation zwischen mehreren Kurven.
 * Code in [dystonse-gtfs-data](https://github.com/dystonse/dystonse-gtfs-data) aufger√§umt / umstrukturiert f√ºr mehr √úbersichtlichkeit.
 * **Erste statistische Analysen der gesammelten Versp√§tungsdaten unter Verwendung der Kurven. Das ist ein riesiger, ganz zentraler Meilenstein, der sehr bald seinen eigenen Blogpost zur Erl√§uterung verdient!**

Im Folgengen ein kleines Beispiel f√ºr die Analysen.

![Beispielkurve](img/curve_example_1.svg)

Zu sehen ist die Stra√üenbahnlinie 1 in Bremen. Auf der X-Achse ist ihre Versp√§tung an der Endhaltestelle in Sekunden aufgetragen, und die Y-Achse zeigt die Wahrscheinlichkeit, dass die Bahn h√∂chsten so viel versp√§tet ist. Alle Daten (einige Tausend Echtzeitaufzeichnungen) wurden danach gruppiert, wie viel versp√§tung die selbe Bahn zwei Haltestellen zuvor hatte, und f√ºr jede solche Gruppe eine Kurve erzeugt.

Unsere Software erstellt eine solche Grafik durchschnittlich innerhalb von 85ms, inkl. des Einlesens des Fahrplans und der Abfrage der Daten aus der Datenbank.
 
 ### Das machen wir diese Woche
 * Weitere Funktionen f√ºr die Prognoseberechnung mit den neuen Kurven
 * M√∂glichkeit, die Daten in nicht-grafischer Form abzuspeichern
 * Blogpost √ºber die Bedeutung dieser Kurven, also was sie darstellen und warum sie so zentral f√ºr unser Projekt sind 
 
 ### Das bremst uns gerade
 * Andere Jobs und private Aufgaben
 * Schlechte Stimmung wegen der allgemeinen Lage auf der Welt
 
 ### Das motiviert uns gerade
 * Wir arbeiten endlich an einem wichtigen Kernst√ºck unseres Projekts, bei dem wir mit den gesammelten Daten tats√§chlich etwas n√ºtzliches anfangen k√∂nnen.
 * Lenas anderer Job ist jetzt zu Ende - das hei√üt mehr Zeit und Energie f√ºr dieses Projekt.

## Woche 12 (Update zum 25. Mai)
### An diesen Milestones arbeiten wir gerade
 1. [Kontinuierliche Versp√§tungs-Datensammlung planen, aufbauen und betreiben](https://github.com/dystonse/dystonse/milestone/1) (ab jetzt haupts√§chlich nur noch der "betreiben"-Anteil)
 2. [Statistische Analyse der gesammelten Echtzeit-Versp√§tungs-Daten](https://github.com/dystonse/dystonse/milestone/2)
 3. [Prognose-Berechnung entwickeln](https://github.com/dystonse/dystonse/milestone/3) 
 
 ### Das haben wir letzte Woche gemacht 
 * Datenstrukturen f√ºr ein zentrales Konzept unseres Projekts in Programmcode umgesetzt: [Kurven](https://github.com/dystonse/dystonse-curves) f√ºr die kumulierte Wahrscheinlichkeit in verschiedenen Varianten.
 * Grafische Darstellung der Kurven mit [gnuplot](https://docs.rs/gnuplot/0.0.36/gnuplot/) ausprobiert und als Beispiele in unseren Code eingebaut.
 
 ### Das machen wir diese Woche
 * Die Kurven-Datenstrukturen und ihre grafische Darstellung um weitere Funktionen erg√§nzen.
 * Ausprobieren, wie wir die Berechnungen auf den Kurven mit den gesammelten Daten aus der Datenbank verkn√ºpfen k√∂nnen, um daraus die Prognosen zu generieren.
 
 ### Das bremst uns gerade
 * Private Angelegenheiten hier zuhause sind gerade immer noch stressig.
 
 ### Das motiviert uns gerade
 * Mit den Kurven haben wir einen neuen Abschnitt unseres Projekts in Angriff genommen, an dem wir jetzt direkt neue Fortschritte sehen k√∂nnen.

## Woche 11 (Update zum 18. Mai)
### An diesen Milestones arbeiten wir gerade
 1. [Kontinuierliche Versp√§tungs-Datensammlung planen, aufbauen und betreiben](https://github.com/dystonse/dystonse/milestone/1) (ab jetzt haupts√§chlich nur noch der "betreiben"-Anteil)
 2. [Statistische Analyse der gesammelten Echtzeit-Versp√§tungs-Daten](https://github.com/dystonse/dystonse/milestone/2)
 3. [Prognose-Berechnung entwickeln](https://github.com/dystonse/dystonse/milestone/3)
 
 ### Das haben wir letzte Woche gemacht 
 * Anpassung des Analysetools an das neue Datenbankschema fertiggestellt.
 * [Readme-Datei unseres Haupt-Repos](https://github.com/dystonse/dystonse/blob/master/README.md) aktualisiert mit Links zu den neuen Projekt-Repos und Infos, woran wir gerade arbeiten.
 * Monitoring unserer Datensammlung verbessert.
 
 ### Das machen wir diese Woche
 * Analysetool erweitern
 * Hoffentlich mit der Prognoseberechnung anfangen
 
 ### Das bremst uns gerade
 * Wir waren letzte Woche beide etwas krank und haben daher nicht viel geschafft.
 * Private Angelegenheiten hier zuhause sind gerade immer noch stressig.
 
 ### Das motiviert uns gerade
 * Dadurch, dass die Datenbank jetzt schnell l√§uft, k√∂nnen wir viel mehr mit den Daten anfangen und haben weniger nervige Wartezeiten.

## Woche 10 (Update zum 11. Mai)
### An diesen Milestones arbeiten wir gerade
 1. [Kontinuierliche Versp√§tungs-Datensammlung planen, aufbauen und betreiben](https://github.com/dystonse/dystonse/milestone/1) (ab jetzt haupts√§chlich nur noch der "betreiben"-Anteil)
 2. [Statistische Analyse der gesammelten Echtzeit-Versp√§tungs-Daten](https://github.com/dystonse/dystonse/milestone/2)
 3. [Prognose-Berechnung entwickeln](https://github.com/dystonse/dystonse/milestone/3)
 
 ### Das haben wir letzte Woche gemacht 
 * Den Datenbankserver um eine SSD erweitert.
 * [Datenbankschema umgestellt](https://github.com/dystonse/dystonse-docker/commit/94dbb56b310636ca1f30b2016aed540d8656a1c8), so dass wir weniger Speicherplatz brauchen. Jetzt passt unsere gesamte Datenbank in den Cache. Dadurch, und durch einen anderen Prim√§rindex, sind unsere Abfragen darauf nun wieder sehr viel schneller.
 * [Importer an das neue Schema angepasst](https://github.com/dystonse/dystonse-gtfs-data/commit/dd1cf85c6b4836d8703230016807f8954966c0a8).
 * Alle Daten neu importiert.
 * Vorgespr√§ch zum Coaching.
 
 ### Das machen wir diese Woche
 * Analysetool (das derzeit Bildfahrpl√§ne generiert) an das neue Schema anpassen (bereits angefangen).
 * Weitere Analysefunktionen implementieren (gem√§√ü der Planungen der letzten zwei Wochen).
 
 ### Das bremst uns gerade
 * Private Angelegenheiten brauchen gerade viel Energie.
 
 ### Das motiviert uns gerade
 * Lena hat ihren anderen Job verloren und deshalb ab Juni mehr Zeit und vor allem mehr Konzentration f√ºr Dystonse. (Klingt komisch, ist aber wirklich v√∂llig ok so.)
 


## Woche 9 (Update zum 4. Mai)
### An diesen Milestones arbeiten wir gerade
 1. [Kontinuierliche Versp√§tungs-Datensammlung planen, aufbauen und betreiben](https://github.com/dystonse/dystonse/milestone/1) (ab jetzt haupts√§chlich nur noch der "betreiben"-Anteil)
 2. [Statistische Analyse der gesammelten Echtzeit-Versp√§tungs-Daten](https://github.com/dystonse/dystonse/milestone/2)
 3. [Prognose-Berechnung entwickeln](https://github.com/dystonse/dystonse/milestone/3)
 
 ### Das haben wir letzte Woche gemacht 
 * Ein mathematisches Konzept f√ºr die komprimierte Speicherung der gesammelten Versp√§tungsdaten entwickelt, um Speicherplatz zu sparen und schnelle Zugriffe zu erm√∂glichen.
 * Verschiedene organisatorische Dinge
 
 ### Das machen wir diese Woche
 * Recherche zu Server-Angeboten, um unsere Infrastruktur langfristig au√üerhalb unseres Home Office betreiben zu k√∂nnen
 * Bisherigen Code etwas aufr√§umen
 * Komprimiertes Speicherkonzept in Programmcode umsetzen
 * Weitere manuelle / grafische Analysen unserer gesammelten Daten
 
 ### Das bremst uns gerade
 * Wir sind allgemein etwas ersch√∂pft und haben letzte Woche nicht viel geschafft
 
 ### Das motiviert uns gerade
 * Die erste Auszahlung von unserem F√∂rdergeld ist inzwischen angekommen
 * Bald f√§ngt unser erstes Coaching an
 

## Woche 8 (Update zum 27. April)
### An diesen Milestones arbeiten wir gerade
 1. [Kontinuierliche Versp√§tungs-Datensammlung planen, aufbauen und betreiben](https://github.com/dystonse/dystonse/milestone/1) (ab jetzt haupts√§chlich nur noch der "betreiben"-Anteil)
 2. [Statistische Analyse der gesammelten Echtzeit-Versp√§tungs-Daten](https://github.com/dystonse/dystonse/milestone/2)
 3. [Prognose-Berechnung entwickeln](https://github.com/dystonse/dystonse/milestone/3)
 
### Das haben wir letzte Woche gemacht 
 * Infos √ºber asynchrone Funktionen in Rust recherchiert, um rauszufinden, ob wir damit unsere Berechnungen evtl. beschleunigen k√∂nnen.
 * [Diagramme](https://twitter.com/dystonse/status/1253389857935757318) erstellt, um zu visualisieren, wie sich die Versp√§tung eines Busses zwischen verschiedenen Haltestellen ver√§ndert - dabei haben wir leider einige unplausible Auff√§lligkeiten in den Daten bemerkt.
 * Diverse organisatorische Aufgaben im Rahmen unserer F√∂rderung.
 
### Das machen wir diese Woche
 * Planung, Recherche und √úberlegung, wie wir mit den bisherigen Daten besser arbeiten k√∂nnen und/oder weitere Datenquellen suchen.
 * Umsetzung davon, je nachdem was dabei rauskommt.
 * Datenstrukturen f√ºr die Prognose-Komponente definieren.
 * Weitere organisatorische Aufgaben nachholen, die zwischendurch liegen geblieben sind.

### Das bremst uns gerade
 * Andere Jobs und private Aufgaben
 * Die Arbeit mit der Datenbank und den fehlerhaften Daten ist oft frustrierend.
 * Unser erstes F√∂rdergeld ist immer noch nicht angekommen und wir werden langsam nerv√∂s, ob wir mit dem Geld von unseren anderen Jobs alleine noch finanziell √ºber den Monatswechsel kommen.

### Das motiviert uns gerade
 * Home Office zu zweit funktioniert immer noch gut.
 * Bald kommen wieder spannende Programmieraufgaben auf uns zu.

## Woche 7 (Update zum 20. April)
### An diesen Milestones arbeiten wir gerade
 1. [Kontinuierliche Versp√§tungs-Datensammlung planen, aufbauen und betreiben](https://github.com/dystonse/dystonse/milestone/1) (ab jetzt haupts√§chlich nur noch der "betreiben"-Anteil)
 2. [Statistische Analyse der gesammelten Echtzeit-Versp√§tungs-Daten](https://github.com/dystonse/dystonse/milestone/2)
 3. [Prognose-Berechnung entwickeln](https://github.com/dystonse/dystonse/milestone/3)
 
### Das haben wir letzte Woche gemacht 
 * Die Generierung von Bildfahrpl√§nen verbessert.
 * Datenbank-Indizes verbessert (und dabei viel ausprobiert und gelernt), damit die Abfragen auf unserer gro√üen Datenmenge trotzdem noch in brauchbarer Zeit fertig werden.
 * Einen ausf√ºhrlichen [Blogpost](http://blog.dystonse.org/opendata/2020/04/20/datensammlung-2.html) √ºber unsere Fortschritte des letzten Monats vorbereitet.
 
### Das machen wir diese Woche
 * Die Datenbank weiter verbessern (vor allem: beschleunigen), ggf. neu aufsetzen falls n√∂tig.
 * Datenanalysen nicht nur "mit den Augen" durch Bildfahrpl√§ne, sondern als statistische Zahlenwerte.

### Das bremst uns gerade
 * Andere Jobs und private Aufgaben
 * Viele unserer Datens√§tze wirken trotz insgesamt gro√üer Mengen noch so l√ºckenhaft, dass wir m√∂glicherweise bald noch weitere Quellen suchen m√ºssen, deren Daten weniger fehlerhaft sind (aber daf√ºr dann wahrscheinlich noch nicht so _richtig_ Open Data).
 
### Das motiviert uns gerade
 * Die erste Auszahlung unseres F√∂rdergeldes kommt wahrscheinlich bald bei uns an.
 
## Woche 6 (Update zum ~~13.~~ 14. April)
### An diesen Milestones arbeiten wir gerade
 1. [Kontinuierliche Versp√§tungs-Datensammlung planen, aufbauen und betreiben](https://github.com/dystonse/dystonse/milestone/1) (ab jetzt haupts√§chlich nur noch der "betreiben"-Anteil)
 2. [Statistische Analyse der gesammelten Echtzeit-Versp√§tungs-Daten](https://github.com/dystonse/dystonse/milestone/2)
 3. [Prognose-Berechnung entwickeln](https://github.com/dystonse/dystonse/milestone/3)

### Das haben wir letzte Woche gemacht
(wie immer: viel Text, aber diesmal auch ein paar Bilder!)

 * Einfache, quantitative Visualisierungen der bisher gesammelten Daten, um die Menge und Qualit√§t der Daten einzusch√§tzen (schwankt leider sehr).
 * Versuch, die verschiedenen Varianten von (Bus-)Linien zu verstehen und algorithmisch zu verarbeiten. Dabei entstehen unhandliche Grafiken wie die folgende: [haltestellen_03.png](img/haltestellen_03.png).
 * Visualisierung von einzelnen (Sub)Routen in Raum-Zeit-Diagrammen im Stil von [Bildfahrpl√§nen](https://de.wikipedia.org/wiki/Bildfahrplan) als neue Funktion unseres [dystonse-gtfs-data](https://github.com/dystonse/dystonse-gtfs-data)-Tools implementiert. Beispiel siehe unten.
 * Die Datenstrukturen f√ºr `Trip`s im Paket [gtfs-structures](https://github.com/rust-transit/gtfs-structure) um ein Feld f√ºr die optionale `shape_id` aus dem GTFS-Standard erweitert, die wir auch f√ºr unsere Visualisierung nutzen, und daf√ºr einen Pull request erstellt.
 * In unserer Version der [gtfs-structures](https://github.com/dystonse/gtfs-structure) ein neues Feld `route_variant` eingef√ºhrt, dessen Wert aus der Haltestellen-Abfolge berechnet wird (damit weichen wir zwar vom GTFS-Standard ab, aber es ist zuverl√§ssiger, da die optionale `shape_id` von einem der Anbieter, die wir aktuell verwenden, oft nicht angegeben wird.)
 * Ein neues [Repository f√ºr manuelle Tests](https://github.com/dystonse/dystonse-tests) angelegt, um f√ºr "mal eben schnell gucken, ob die Daten jetzt richtig aussehen" weniger in unserem eigentlichen Code rumbasteln zu m√ºssen.

### Bilder
Die Menge der Datenpunkte, die wir pro Stunde sammeln konnten. Der blaue Graph zeigt Daten aus dem _VRN (Verkehrsverbund Rhein Neckar)_ und der gr√ºne aus dem _VBN (Verkehrsverbund Bremen Niedersachsen)_.

![Datenmenge](img/Datenmenge_03.png)

Hier ein Beispiel f√ºr einen von uns generierten Bildfahrplan:

![Bildfahrplan](img/Bildfahrplan_01.png)

Auf der Y-Achse schreitet von unten nach oben die Zeit voran, hier also von etwa 12:00 bis 18:00. Von links nach rechts verl√§uft die Buslinie 430 in Oldenburg. Die Bedeutung der Linien je nach Farbe:

 * **schwarz:** Der Verlauf laut Fahrplan
 * **gr√ºn:** Reale Fahrten an einem Wochentag
 * **rot:** Reale Fahrten an einem Sonntag

### Das machen wir diese Woche
 * Datenqualit√§t sichten und pr√ºfen, ob wir systematische Fehler beim Sammeln / Import gemacht haben
 * ggf. Fehler beheben und neu importieren
 * weitere Analyse der Echtzeitdaten, auf dass wir bald zu einem statistischen Modell f√ºr die Prognose kommen
 * ggf. neuer Blog-Post zu unseren Erkenntnissen und Zwischenergebnissen
 
### Das bremst uns gerade
 * Andere Jobs und private Aufgaben
 * die ungewisse Zukunft (Absage vieler Veranstaltungen etc. durch die Corona-Krise) dr√ºckt mittlerweile schon etwas auf unsere Stimmung und Energie

### Das motiviert uns gerade
 * Mit der Visualisierung der Daten haben wir direkt etwas sichtbares als Ergebnis.

## Woche 5 (Update zum 6. April)
### An diesen Milestones arbeiten wir gerade
 1. [Kontinuierliche Versp√§tungs-Datensammlung planen, aufbauen und betreiben](https://github.com/dystonse/dystonse/milestone/1) (ab jetzt haupts√§chlich nur noch der "betreiben"-Anteil)
 2. [Statistische Analyse der gesammelten Echtzeit-Versp√§tungs-Daten](https://github.com/dystonse/dystonse/milestone/2)
 3. [Prognose-Berechnung entwickeln](https://github.com/dystonse/dystonse/milestone/3)

### Das haben wir letzte Woche gemacht
 * Fehlerbehandlung und Ausgabe von Erfolgsstatistiken im [Importer](https://github.com/dystonse/dystonse-gtfs-importer) verbessert.
 * Datensammlung und -import f√ºr eine weitere Datenquelle eingerichtet, so dass wir nun Daten von [VBN](https://www.vbn.de/) und [VRN](https://www.vrn.de/) gleichzeitig aufzeichnen.
 * Fr√ºher gesammelte Daten (von unserem ersten Testserver) zus√§tzlich in die aktuell genutzte Datenbank importiert.

### Das machen wir diese Woche
 * Erste statistische Analysen der bisher gesammelten Daten, um ein Gef√ºhl daf√ºr zu bekommen, mit welchen Einflussfaktoren wir beim Prognose-Modul anfangen.
 * Mit der Entwicklung der Software-Komponente f√ºr die Prognoseberechnung beginnen.
 
### Das bremst uns gerade
 * Nachdem wir im vorigen Monat recht viel Zeit in dieses Projekt gesteckt hatten, haben wir uns letzte Woche etwas mehr Zeit f√ºr Erholung genommen und uns mehr um private Angelegenheiten gek√ºmmert.

### Das motiviert uns gerade
 * Programmieren in Rust macht Spa√ü
 * Wir haben unsere erste wichtige Komponente im Wesentlichen fertig und k√∂nnen jetzt bald mit ganz neuen Teilen anfangen


## Woche 4 (Update zum 30. M√§rz)
### An diesen Milestones arbeiten wir gerade
 1. [Kontinuierliche Versp√§tungs-Datensammlung planen, aufbauen und betreiben](https://github.com/dystonse/dystonse/milestone/1)
 2. [Statistische Analyse der gesammelten Echtzeit-Versp√§tungs-Daten](https://github.com/dystonse/dystonse/milestone/2)

### Das haben wir letzte Woche gemacht
 * Datensammlungs-Skripte und Importer in [Docker-Setup](https://github.com/dystonse/dystonse-docker) integriert
 * [Importer](https://github.com/dystonse/dystonse-gtfs-importer) so erweitert, dass mehrere Dateien auf einmal verarbeitet werden k√∂nnen.
 * Anschlie√üend automatischen Modus hinzugef√ºgt, mit dem kontinuierlich neue Daten erkannt und in die Datenbank importiert werden.

### Das machen wir diese Woche
 * Datensammlung robuster machen (Fehlerbehandlung, Monitoring, etc.)
 * Analyse der bisher gesammelten Daten (zun√§chst Datenqualit√§t und -Menge, dann Statistik √ºber Versp√§tungen)
 * Anlegen von neuen Datenquellen automatisieren 
 * evtl. mit der Entwicklung der Software-Komponente f√ºr die Prognoseberechnung beginnen
 
### Das bremst uns gerade
 * Durch das Corona-Virus ist Nahverkehr gerade kein besonders popul√§res Thema, was z.B. Nutzer\*innen-Befragungen schwierig machen k√∂nnte
 * andere Jobs und Verpflichtungen

### Das motiviert uns gerade
 * Dass wir zwei gemeinsam im selben Homeoffice arbeiten k√∂nnen (das sogenannte "Social Dystonsing" üòâ)

## Woche 3 (Update zum 23. M√§rz)
### An diesen Milestones arbeiten wir gerade
 1. [Kontinuierliche Versp√§tungs-Datensammlung planen, aufbauen und betreiben](https://github.com/dystonse/dystonse/milestone/1)
 2. [Statistische Analyse der gesammelten Echtzeit-Versp√§tungs-Daten](https://github.com/dystonse/dystonse/milestone/2)
 3. [Prognose-Berechnung entwickeln](https://github.com/dystonse/dystonse/milestone/3)

### Das haben wir letzte Woche gemacht
 * Langzeitarchivierung von Fahrplandaten in git getestet - geht nur so m√§√üig, daher erstmal verworfen
 * MacMini mit Debian und Docker eingerichtet, um Raspberry Pi zu ersetzen/erg√§nzen
 * [docker-compose-Konfiguration](https://github.com/dystonse/dystonse-docker) f√ºr Datenbank(-administration) aufgesetzt
 * Angefangen, die Programmiersprache Rust zu lernen
 * [Importer](https://github.com/dystonse/docker-rust-test) in Rust geschrieben, der folgendes tut:
   * Fahrplandaten (aus gtfs) einlesen. Wir haben das auf drei verschiedene Weisen getestet:
     * zun√§chst mit [`gtfsdb`](https://github.com/OpenTransitTools/gtfsdb) (sehr langsam)
     * dann mit [`gtfs-structures`](https://github.com/rust-transit/gtfs-structure) (133 mal schneller als `gtfsdb`)
     * [`csv`](https://crates.io/crates/csv) selbst parsen (weitere 30 mal schneller als `gtfs-structures`, aber unpraktisch, daher verworfen)
   * Echtzeitdaten (aus gtfs-realtime) einlesen
   * Daten miteinander referenzieren
   * Daten in Datenbank schreiben
 * Definiert und [Notizen](Notizen%20zur%20Prognoseberechnung.md) dazu gemacht, was die Ein- und Ausgabeparameter der Prognose sind

### Das machen wir diese Woche
 * Analyse der bisher gesammelten Daten
 * Software-Komponente f√ºr die Prognoseberechnung entwickeln
 * mehr Rust lernen
 
### Das bremst uns gerade
 * Im Zuge der Covid-19-Pr√§vention wurden gro√üe Teile des Nahverkehrs eingestellt, dadurch bekommen wir praktisch keine Echzeitdaten mehr. Zum Gl√ºck haben wir einige Tage zuvor mit der Aufzeichnung begonnen
 * Das Cross-Compiling mit `docker buildx` schl√§gt nun [wegen eines bekannten Bugs](https://github.com/dystonse/docker-rust-test#known-problems-with-cross-compiling) fehl, f√ºr den es noch keine verf√ºgare L√∂sung gibt

### Das motiviert uns gerade
 * Rust ist eine spannende Sprache, und sich darin einzuarbeiten ist anspruchsvoll, aber eben auch motivierend


## Woche 3 (Update zum 23. M√§rz)
### An diesen Milestones arbeiten wir gerade
 1. [Kontinuierliche Versp√§tungs-Datensammlung planen, aufbauen und betreiben](https://github.com/dystonse/dystonse/milestone/1)
 2. [Statistische Analyse der gesammelten Echtzeit-Versp√§tungs-Daten](https://github.com/dystonse/dystonse/milestone/2)
 3. [Prognose-Berechnung entwickeln](https://github.com/dystonse/dystonse/milestone/3)

### Das haben wir letzte Woche gemacht
 * Langzeitarchivierung von Fahrplandaten in git getestet - geht nur so m√§√üig, daher erstmal verworfen
 * MacMini mit Debian und Docker eingerichtet, um Raspberry Pi zu ersetzen/erg√§nzen
 * [docker-compose-Konfiguration](https://github.com/dystonse/dystonse-docker) f√ºr Datenbank(-administration) aufgesetzt
 * Angefangen, die Programmiersprache Rust zu lernen
 * [Importer](https://github.com/dystonse/docker-rust-test) in Rust geschrieben, der folgendes tut:
   * Fahrplandaten (aus gtfs) einlesen. Wir haben das auf drei verschiedene Weisen getestet:
     * zun√§chst mit [`gtfsdb`](https://github.com/OpenTransitTools/gtfsdb) (sehr langsam)
     * dann mit [`gtfs-structures`](https://github.com/rust-transit/gtfs-structure) (133 mal schneller als `gtfsdb`)
     * [`csv`](https://crates.io/crates/csv) selbst parsen (weitere 30 mal schneller als `gtfs-structures`, aber unpraktisch, daher verworfen)
   * Echtzeitdaten (aus gtfs-realtime) einlesen
   * Daten miteinander referenzieren
   * Daten in Datenbank schreiben
 * Definiert und [Notizen](Notizen%20zur%20Prognoseberechnung.md) dazu gemacht, was die Ein- und Ausgabeparameter der Prognose sind

### Das machen wir diese Woche
 * Analyse der bisher gesammelten Daten
 * Software-Komponente f√ºr die Prognoseberechnung entwickeln
 * mehr Rust lernen
 
### Das bremst uns gerade
 * Im Zuge der Covid-19-Pr√§vention wurden gro√üe Teile des Nahverkehrs eingestellt, dadurch bekommen wir praktisch keine Echzeitdaten mehr. Zum Gl√ºck haben wir einige Tage zuvor mit der Aufzeichnung begonnen
 * Das Cross-Compiling mit `docker buildx` schl√§gt nun [wegen eines bekannten Bugs](https://github.com/dystonse/docker-rust-test#known-problems-with-cross-compiling) fehl, f√ºr den es noch keine verf√ºgare L√∂sung gibt

### Das motiviert uns gerade
 * Rust ist eine spannende Sprache, und sich darin einzuarbeiten ist anspruchsvoll, aber eben auch motivierend


## Woche 2 (Update zum 16. M√§rz)
### An diesen Milestones arbeiten wir gerade
 1. [Kontinuierliche Versp√§tungs-Datensammlung planen, aufbauen und betreiben](https://github.com/dystonse/dystonse/milestone/1)

### Das haben wir letzte Woche gemacht
 * Weitere Datenquellen gefunden, darunter Echtzeitdaten f√ºr 2100 Fahrzeuge in Niedersachsen
 * [Bekannte Datenquellen in einem maschinenlesbaren JSON-Format](datasources.json) niedergeschrieben
 * √úbersicht √ºber alle Verkehrsunternehmen Deutschlands gestartet, dazu [ein paar kleine Tools](https://github.com/dystonse/dystonse-tools/tree/master/agencies) geschrieben
 * [Versuche mit `docker buildx`](https://github.com/dystonse/docker-rust-test), um unseren k√ºnftigen Rust-Code gleich f√ºr mehrere Architekturen (amd64, armv7) zu bauen und zu deployen
 * Einen Raspberry Pi als Versuchsserver mit Docker eingerichtet
 * Mit GitHub Pages einen Blog auf [blog.dystonse.org](https://blog.dystonse.org/) eingerichtet und ersten [Blogpost √ºber Datensammlung](http://blog.dystonse.org/opendata/2020/03/13/datensammlung.html) ver√∂ffentlicht
 * Simples Skript zur Aufzeichnung der Echtzeitdaten (alle 2 Minuten) und der Fahrpl√§ne (1 mal t√§glich) geschrieben und in Betrieb genommen
 * Manuell gepr√ºft, ob die Echtzeitdaten sich mit dem Fahrplan referenzieren lassen (ja, es geht)

### Das machen wir diese Woche
 * Die Daten nicht nur einfach als Datei herunterladen, sondern in Datenbanken speichern
 * Erste statistische Auswertungen √ºber die Daten
 * MacMini in Betrieb nehmen, der den Raspberry Pi unterst√ºtzt oder ersetzt
 * Die Sammel- und Analysevorg√§nge dockerisieren, damit wir sie sp√§ter leichter auf weitere Datenquellen ausweiten k√∂nnen
 * Zwei Ideen zur speichereffizienten Langzeitarchivierung von Fahrplanversionen ausformulieren und ver√∂ffentlichen (wir sind noch nicht sicher, ob wir die je umsetzen werden)
  
### Das bremst uns gerade
 * F√ºrchterliche Dokumentation von GitHub Pages, Ausf√§lle bei GitHub (inzwischen behoben)
 * Andere Jobs und private Aufgaben

### Das motiviert uns gerade
 * Dass unser Zuwendungsbescheid nun doch angekommen ist
 * Dass wir endlich eine brauchbare Datenquelle gefunden haben

## Woche 1 (Update zum 9. M√§rz)

### An diesen Milestones arbeiten wir gerade
 1. [Kontinuierliche Versp√§tungs-Datensammlung planen, aufbauen und betreiben](https://github.com/dystonse/dystonse/milestone/1)

### Das haben wir letzte Woche gemacht
 * Mit Abstand der gr√∂√üte Brocken Arbeit in dieser Woche: Potentielle [Datenquellen](./Datenquellen.md) und [-Formate](./Datenformate.md) f√ºr Echtzeitdaten recherchiert.
 * Mit [Jannis](https://github.com/derhuerst) getroffen, der Open Data und Open Source rund um den Berliner Nahverkehr macht
 * Ein kleines [Fotoshooting in der Berliner U-Bahn](https://twitter.com/dystonse/status/1235250055084494849) :)
 * Etwas Finanz- und Papierkram
 * Strukturierte [Notizen](./Notizen.md) gemacht
 * Softwarekomponenten und Datenfl√ºsse [√ºberlegt](./Komponenten.md) und in ein [Diagramm](https://github.com/dystonse/dystonse/blob/master/project-status/Dystonse%20Komponenten.png) gegossen
 * Milestones √ºberarbeitet und [in GitHub eingepflegt](https://github.com/dystonse/dystonse/milestones?direction=asc&sort=title&state=open)
 * Die Lizenz bzw. Nutzungsbedingungen f√ºr Echtzeitdaten in M√ºnster [erfragt](https://twitter.com/dystonse/status/1235241688278458369) und erfahren, dass die alles andere als offen sind
 * Auf Twitter nach offenen Daten gefragt und tats√§chlich mehrere gute Hinweise bekommen
 * Testweise ein kleines [Docker-Setup](https://github.com/dystonse/gtfs-collector/blob/master/VRN.env) aufgesetzt und eine Zeit lang Fahrplan- und Echtzeit-Daten aus dem VRN erfolgreich aufgezeichnet

### Das machen wir diese Woche
 * Entscheiden, welche Region als erste Testregion in Frage kommt
 * zuverl√§ssige Datensammlung f√ºr diese Region vorbereiten
 * Fahrplandaten von [gtfs.de](https://gtfs.de/) evaluieren und in Datenbank importieren

### Das bremst uns gerade
 * Die Unsicherheit, da unser F√∂rderbescheid noch nicht da ist
 * Andere Jobs und private Aufgaben
 * Dass die Informationen dar√ºber, wo es Echtzeitdaten als Open Data gibt, selbst nicht strukturiert und offen zug√§nglich ist, und generell vieles noch nicht offen ist

### Das motiviert uns gerade
 * Dass es endlich los geht und wir viel gutes Feedback aus der Community (vorallem √ºber Twitter) bekommen
 * Die vielen Ecken und Enden, an denen wir etwas tun k√∂nnen
 * Dass 2024 die n√∂tigen Echtzeitdaten f√ºr ganz Deutschland offen sein werden, und wir dann schon die passende Software haben werden

_und hier das Template f√ºr k√ºnftige Wochen:_

## Woche X (Update zum X. Xxx)
### An diesen Milestones arbeiten wir gerade
 1. [Kontinuierliche Versp√§tungs-Datensammlung planen, aufbauen und betreiben](https://github.com/dystonse/dystonse/milestone/1)

### Das haben wir letzte Woche gemacht
 * ?

### Das machen wir diese Woche
 * ?
 
### Das bremst uns gerade
 * ?

### Das motiviert uns gerade
 * ?
